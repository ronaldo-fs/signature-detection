{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyPSicsUQYdn2NmeIO7ZM1TT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ronaldo-fs/signature-detection/blob/main/new_signature_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reconhecimento de assinaturas"
      ],
      "metadata": {
        "id": "wGkQBfxoJpQG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Definição do Problema"
      ],
      "metadata": {
        "id": "MeG0ERUCN1Gf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reconhecer e entender as características exclusivas de uma assinatura em um documento envolve detectar padrões, formas e características específicas que a diferenciam de outros elementos, como texto ou desenhos."
      ],
      "metadata": {
        "id": "bTKS2j3rJyRa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ao lidar com um problema de reconhecimento de assinaturas, algumas premissas e hipóteses podem ser consideradas, incluindo:\n",
        "1.   **Estabilidade da assinatura:** Cada assinatura mantém características consistentes que permitem sua distinção de outras.\n",
        "2.   **Qualidade da imagem:** A qualidade das imagens é adequada para garantir uma identificação precisa.\n",
        "3.   **Representatividade do conjunto de dados:** O conjunto de dados utilizado reflete adequadamente a diversidade de assinaturas reais.\n",
        "4.   **Uniformidade do meio de assinatura:** As assinaturas são examinadas em um meio uniforme, minimizando variações.\n",
        "5.   **Ausência de manipulação maliciosa:** Não há tentativas deliberadas de adulterar ou falsificar assinaturas."
      ],
      "metadata": {
        "id": "7Dwx1-IuJ2EX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ao realizar a busca de documentos com assinaturas para seleção de dados, algumas restrições ou condições para garantir a qualidade e representatividade do conjunto de dados, foram:\n",
        "1.  **Variedade de fontes:** Buscar documentos de diferentes tipos, como contratos, formulários e recibos.\n",
        "2.  **Amostragem representativa:** Selecionar uma amostra diversificada que capture diferentes estilos de assinatura.\n",
        "3.  **Tamanho da amostra:** Escolher um tamanho suficiente para representar a diversidade, mas que seja gerenciável para análise.\n",
        "4.  **Consentimento e privacidade:** Garantir consentimento e proteger a privacidade dos indivíduos cujas assinaturas estão sendo utilizadas."
      ],
      "metadata": {
        "id": "OdAjUKO-J7P3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Importação das bibliotecas"
      ],
      "metadata": {
        "id": "d93ENrz9KIYu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PqsOfIA9Jh0u"
      },
      "outputs": [],
      "source": [
        "# Importação das bibliotecas\n",
        "import xml.etree.ElementTree as ET\n",
        "import os, sys, json, shutil\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import locale\n",
        "from glob import glob\n",
        "from google.colab import userdata\n",
        "from IPython.display import display, Image\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sobre o conjunto de dados:"
      ],
      "metadata": {
        "id": "zDZp2pxsKnBf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "São 1290 imagens TIFF de documentos acompanhadas por 1290 arquivos XML. Cada arquivo XML contém informações específicas relacionadas a uma imagem TIFF. Além disso, o texto está em fonte preta sobre fundo branco.\n",
        "*   Algumas informações sobre o XML podem incluir:\n",
        "  *   Etiqueta DL_PAGE:\n",
        "      *   `src`, qual arquivo de imagem corresponde às informações do XML\n",
        "      *   Altura e largura da página\n",
        "  *   Etiqueta DL_ZONE:\n",
        "      *   `gedi_type`, tipo de objeto detectado, como \"DLLogo\" ou \"DLSignature\"\n",
        "      *   Coordenadas (linha, coluna, altura e largura) do objeto\n",
        "\n",
        "De 1290 imagens TIFF:\n",
        "*   430 imagens não tiveram objetos detectados\n",
        "*   373 imagens tiveram 1 assinatura detectada\n",
        "*   84 imagens tiveram 1 logo de empresa detectado\n",
        "*   306 imagens tiveram 1 assinatura e 1 logo de empresa detectados\n",
        "*   55 imagens tiveram 2 assinaturas detectadas\n",
        "*   42 imagens tiveram mais de 2 objetos detectados"
      ],
      "metadata": {
        "id": "fnkPy4rDKsus"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Download do dataset"
      ],
      "metadata": {
        "id": "dDhmf5jqKz3L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para conectar o Kaggle ao Google Colab e acessar um dataset, as seguintes ações foram realizadas:\n",
        "1.   **Geração da chave API do Kaggle:**\n",
        "  *   Isso resultará no download do arquivo `kaggle.json`, que contém as credenciais de API.\n",
        "  *   As credenciais foram armazenadas como variáveis de segurança no projeto.\n",
        "2.   **Autenticação no Google Colab:**\n",
        "  *   Configure as credenciais para uso no ambiente:"
      ],
      "metadata": {
        "id": "vfby3lQHK33r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Caminho completo do diretório .kaggle\n",
        "kaggleFolder = os.path.expanduser('~/.kaggle')\n",
        "\n",
        "# Verifica se o diretório existe\n",
        "if not os.path.exists(kaggleFolder):\n",
        "    # Cria o diretório se não existir\n",
        "    os.makedirs(kaggleFolder)\n",
        "\n",
        "# Caminho completo do arquivo JSON de autenticação\n",
        "kaggleAuthFile = os.path.join(kaggleFolder, 'kaggle.json')\n",
        "\n",
        "# Cria o arquivo JSON de autenticação\n",
        "with open(kaggleAuthFile, 'w') as jsonFile:\n",
        "    json.dump({\n",
        "        \"username\": userdata.get('kaggleUsr'),\n",
        "        \"key\": userdata.get('kaggleKey')\n",
        "    }, jsonFile)\n",
        "\n",
        "# Define as permissões do arquivo\n",
        "os.chmod(kaggleAuthFile, 0o600)\n",
        "\n",
        "print(\"Arquivo JSON de autenticação criado com sucesso em\", kaggleAuthFile)"
      ],
      "metadata": {
        "id": "bGKT4aV1K7Qz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.   **Instalação da biblioteca do Kaggle:**\n",
        "  *   Instale a biblioteca do Kaggle no Colab usando o seguinte comando:"
      ],
      "metadata": {
        "id": "VVEsx7YGLFAR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalar o pacote kaggle\n",
        "!pip install kaggle"
      ],
      "metadata": {
        "id": "bymJF5n8LIFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.   **Download e acesso ao dataset:**\n",
        "  *   Acesse o dataset desejado no Kaggle [clicando aqui](https://www.kaggle.com/datasets/kaiquanmah/tobacco800-with-ground-truth)\n",
        "  *   Realize o download diretamente no diretório `./datasets/raw/` usando:"
      ],
      "metadata": {
        "id": "BeEkb_CDLMM8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Excluir diretório existente\n",
        "if os.path.exists(\"/content/datasets/\"):\n",
        "    shutil.rmtree(\"/content/datasets/\")\n",
        "\n",
        "# Criar diretório\n",
        "os.makedirs(\"/content/datasets/raw/\")\n",
        "\n",
        "# Fazer download do dataset\n",
        "!kaggle datasets download -d kaiquanmah/tobacco800-with-ground-truth --path /content/datasets/raw --force"
      ],
      "metadata": {
        "id": "83ZHUmZALNYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.  \n",
        "  *   Descompacte o arquivo baixado:"
      ],
      "metadata": {
        "id": "t7cLaEhTLi_O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/datasets/raw/tobacco800-with-ground-truth.zip -d /content/datasets/raw/tobacco800-with-ground-truth/"
      ],
      "metadata": {
        "id": "q_3bkdhNLmaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Conversão do dataset Tobacco 800 para o formato YOLO v8"
      ],
      "metadata": {
        "id": "DobjMfcdMP65"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define os caminhos para acessar o dataset e os arquivos associados à fonte de dados.\n",
        "sourceDatasetPath = '/content/datasets/raw/tobacco800-with-ground-truth'\n",
        "sourceImageFilesPath = f'{sourceDatasetPath}/Tobacco800_SinglePage/Tobacco800_SinglePage/SinglePageTIF'\n",
        "sourceAnnotationFilesPath = f'{sourceDatasetPath}/Tobacc800_Groundtruth_v2.0/Tobacc800_Groundtruth_v2.0/XMLGroundtruth_v2.0'"
      ],
      "metadata": {
        "id": "b-8pZhrCMWxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.  Manipulação e análise de dados estruturados em XML, com o objetivo de extrair informações detalhadas essenciais para o treinamento do YOLO v8. Preparação do dataset e conversão de dados categóricos em formato adequado."
      ],
      "metadata": {
        "id": "3JtcUJYTMgsD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista em ordem alfabética todos os arquivos XML dentro do diretório especificado\n",
        "annotationFiles = sorted(glob(f'{sourceAnnotationFilesPath}/*.xml'))\n",
        "\n",
        "# Inicializa uma lista para armazenar informações extraídas dos arquivos XML\n",
        "extractedData = []\n",
        "\n",
        "# Coletar todas as categorias de todos os nós para treinamento do LabelEncoder\n",
        "allCategories = []\n",
        "for filePath in annotationFiles:\n",
        "    rootElement = ET.parse(filePath).getroot()\n",
        "    for node in rootElement[0][0]:\n",
        "        allCategories.append(node.attrib['gedi_type'])\n",
        "\n",
        "# Treinar o LabelEncoder com todas as categorias coletadas\n",
        "labelEncoder = LabelEncoder()\n",
        "labelEncoder.fit(allCategories)\n",
        "\n",
        "# Processar cada arquivo XML\n",
        "for filePath in annotationFiles:\n",
        "    rootElement = ET.parse(filePath).getroot()\n",
        "    fileName = rootElement[0].attrib['src']\n",
        "    pageHeight = rootElement[0][0].attrib['height']\n",
        "    pageWidth = rootElement[0][0].attrib['width']\n",
        "\n",
        "    # Extrair informações de cada nó na página\n",
        "    for node in rootElement[0][0]:\n",
        "        nodeType = node.attrib['gedi_type']\n",
        "        nodeLabel = labelEncoder.transform([nodeType])[0]\n",
        "\n",
        "        nodeId = node.attrib['id']\n",
        "        xPosition = node.attrib['col']\n",
        "        yPosition = node.attrib['row']\n",
        "        nodeWidth = node.attrib['width']\n",
        "        nodeHeight = node.attrib['height']\n",
        "\n",
        "        if nodeType == 'DLSignature':\n",
        "            authorId = node.attrib.get('AuthorID', 'NA')\n",
        "            isOverlapped = node.attrib.get('Overlapped', 'NA')\n",
        "        else:\n",
        "            authorId, isOverlapped = 'NA', 'NA'\n",
        "\n",
        "        # Construir linha com os dados essenciais\n",
        "        row = [fileName, pageHeight, pageWidth, authorId, isOverlapped, nodeType, nodeLabel, nodeId, xPosition, yPosition, nodeWidth, nodeHeight]\n",
        "        extractedData.append(row)"
      ],
      "metadata": {
        "id": "5moPCvM2Mk3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.  Avaliação da integridade dos dados extraídos, com foco em garantir que foram carregados corretamente e estão prontos para uso nas etapas subsequentes do processo."
      ],
      "metadata": {
        "id": "4Etk7lK4Msed"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xmlExtractedData = pd.DataFrame(extractedData, columns=[\n",
        "    'FileName', 'PageHeight', 'PageWidth', 'AuthorID', 'Overlapped',\n",
        "    'Category', 'Labels', 'ID', 'X', 'Y', 'Width', 'Height'\n",
        "])\n",
        "xmlExtractedData.head(10)"
      ],
      "metadata": {
        "id": "Iq4dmkeqMv1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.  Divisão do DataFrame em dois subconjuntos distintos: um para treinamento e outro para validação. Exibição das dimensões de cada conjunto para proporcionar uma visão clara da distribuição dos dados entre treinamento e validação."
      ],
      "metadata": {
        "id": "r4wdOWDaMz_8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainData, validData = train_test_split(xmlExtractedData, test_size=0.1, random_state=13, shuffle=True)\n",
        "print(trainData.shape, validData.shape)"
      ],
      "metadata": {
        "id": "x-_Xy_ByM129"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.  Construção dos diretórios para receber os dados de treinamento e validação, organizando o ambiente necessário para a alocação estruturada dos subconjuntos de dados."
      ],
      "metadata": {
        "id": "0DQPh7PtM6Fx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/datasets/yolo-format/tobacco800/images/train\n",
        "!mkdir -p /content/datasets/yolo-format/tobacco800/labels/train\n",
        "!mkdir -p /content/datasets/yolo-format/tobacco800/images/val\n",
        "!mkdir -p /content/datasets/yolo-format/tobacco800/labels/val\n",
        "\n",
        "# Define os caminhos para acessar o dataset principal e os arquivos relacionados aos subconjuntos de treinamento e validação.\n",
        "yoloDatasetDirectory = '/content/datasets/yolo-format/tobacco800'\n",
        "\n",
        "trainImagePath = f'{yoloDatasetDirectory}/images/train'\n",
        "trainLabelPath = f'{yoloDatasetDirectory}/labels/train'\n",
        "\n",
        "validImagePath = f'{yoloDatasetDirectory}/images/val'\n",
        "validLabelPath = f'{yoloDatasetDirectory}/labels/val'"
      ],
      "metadata": {
        "id": "PtUmdxg5M-gU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.  Preparação de dados em um formato que o YOLO pode utilizar diretamente para o treinamento e validação de modelos de detecção de objetos."
      ],
      "metadata": {
        "id": "yzRNUA3PNCIF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def segregateData(dataFrame, sourceImagePath, sourceLabelPath, targetImagePath, targetLabelPath):\n",
        "  # Processamento de \"nomes de arquivos\" únicos da coluna 'FileName' do 'DataFrame'\n",
        "  uniqueFilenames = dataFrame['FileName'].unique()\n",
        "\n",
        "  for filename in uniqueFilenames:\n",
        "    # Criando uma máscara para todas as linhas que correspondem ao nome do arquivo\n",
        "    mask = dataFrame['FileName'] == filename\n",
        "\n",
        "    # Converter os tipos de dados para o formato correto\n",
        "    dataFrame.loc[mask, 'Labels'] = dataFrame.loc[mask, 'Labels'].astype(int)\n",
        "    dataFrame.loc[mask, 'X'] = dataFrame.loc[mask, 'X'].astype(float)\n",
        "    dataFrame.loc[mask, 'Y'] = dataFrame.loc[mask, 'Y'].astype(float)\n",
        "    dataFrame.loc[mask, 'Width'] = dataFrame.loc[mask, 'Width'].astype(float)\n",
        "    dataFrame.loc[mask, 'Height'] = dataFrame.loc[mask, 'Height'].astype(float)\n",
        "\n",
        "    # Filtrar o DataFrame para obter apenas as linhas correspondentes ao nome de arquivo específico\n",
        "    subset = dataFrame.loc[mask]\n",
        "\n",
        "    # Converter o DataFrame para o formato YOLO\n",
        "    yoloData = subset[['Labels', 'X', 'Y', 'Width', 'Height']].to_numpy()\n",
        "\n",
        "    # Salvar os dados em arquivos TXT\n",
        "    txtFilename = os.path.join(targetLabelPath, f\"{filename.split('.')[0]}.txt\")\n",
        "    np.savetxt(txtFilename, yoloData, fmt=[\"%d\", \"%f\", \"%f\", \"%f\", \"%f\"])\n",
        "    shutil.copyfile(os.path.join(sourceImagePath, filename), os.path.join(targetImagePath, filename))\n",
        "\n",
        "# Segmentação dos dados em subconjuntos de treinamento e validação\n",
        "segregateData(trainData, sourceImageFilesPath, sourceAnnotationFilesPath, trainImagePath, trainLabelPath)\n",
        "segregateData(validData, sourceImageFilesPath, sourceAnnotationFilesPath, validImagePath, validLabelPath)\n",
        "\n",
        "# Número de arquivos de imagem e rótulos nos diretórios de treinamento e validação\n",
        "print(\"Número de imagens de treinamento:\", len(os.listdir(trainImagePath)))\n",
        "print(\"Número de rótulos de treinamento:\", len(os.listdir(trainLabelPath)))\n",
        "print(\"Número de imagens de validação:\", len(os.listdir(validImagePath)))\n",
        "print(\"Número de rótulos de validação:\", len(os.listdir(validLabelPath)))"
      ],
      "metadata": {
        "id": "syqZwrDrNESX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para este treinamento, não serão utilizados métodos de validação cruzada. Algumas razões para essa decisão são:\n",
        "1.  **Natureza dos dados:** Dados de assinatura real podem ser difíceis de obter em grande quantidade, tornando a divisão em conjuntos de treinamento e teste impraticável.\n",
        "2.  **Complexidade do Modelo:** Métodos simples geralmente são suficientes para a tarefa, eliminando a necessidade de ajustes complexos.\n",
        "3.  **Avaliação direta:** A qualidade da extração de assinatura pode ser facilmente avaliada visualmente, sem a necessidade de métricas de validação cruzada.\n",
        "4.  **Especificidade da tarefa:** A tarefa pode ser altamente específica para cada caso de uso, dependendo mais da qualidade dos dados do que da complexidade do modelo."
      ],
      "metadata": {
        "id": "3OFphvvoNJe5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configuração de hardware, instalação e carregamento do YOLO v8"
      ],
      "metadata": {
        "id": "6vJ0tKSnNOqq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para este treinamento, o algoritmo escolhido foi o de Reconhecimento de Padrões por meio de Redes Neurais Convolucionais (CNNs). As CNNs são altamente eficazes para tarefas de reconhecimento de padrões em imagens, e neste caso específico, optei por utilizar o YOLO v8."
      ],
      "metadata": {
        "id": "p2ssR5GPNSYa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configuração do hardware (GPU) para a execução do YOLO: Acesse o menu 'Editar', depois clique em 'Configurações do notebook' e defina o acelerador de hardware para 'GPU'. Após essa configuração, vamos validar se o hardware foi configurado corretamente e está disponível para uso."
      ],
      "metadata": {
        "id": "gLbFLoZzNTsQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpuInfo = !nvidia-smi\n",
        "gpuInfo = '\\n'.join(gpuInfo)\n",
        "if gpuInfo.find('failed') >= 0:\n",
        "  print('Não conectado a uma GPU.')\n",
        "else:\n",
        "  print(gpuInfo)"
      ],
      "metadata": {
        "id": "tdVV8SPtNYHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalação do pacote `ultralytics` e das [dependências](https://github.com/ultralytics/ultralytics/blob/main/pyproject.toml) necessárias para utilizar o YOLO v8 utilizando o pip e verificação do software para garantir que tudo foi configurado corretamente."
      ],
      "metadata": {
        "id": "PstD6Xz3OPmg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install ultralytics\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ],
      "metadata": {
        "id": "cX6V16wROSUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Definindo o diretório onde o YOLO irá procurar pelos conjuntos de dados no formato correto."
      ],
      "metadata": {
        "id": "BfLG5KaHOYrw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import settings\n",
        "settings.update({\n",
        "  'datasets_dir': '/content/datasets/yolo-format'\n",
        "})"
      ],
      "metadata": {
        "id": "dtvYy9xWSz26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Carregar modelo do YOLO usando\n",
        "\n",
        "  1.  Constrói um novo modelo a partir de um arquivo YAML que descreve a arquitetura do modelo.\n",
        "  2.  Carrega um modelo pré-treinado a partir de um arquivo de pontos de verificação (checkpoint), recomendado para treinamento adicional ou inferência.\n",
        "  3.  Constrói um novo modelo a partir de um arquivo YAML e, em seguida, transfere os pesos de um modelo pré-treinado especificado pelo arquivo de pontos de verificação."
      ],
      "metadata": {
        "id": "tQV0smmDWljp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO('yolov8n.yaml')\n",
        "model = YOLO('yolov8n.pt')\n",
        "model = YOLO('yolov8n.yaml').load('yolov8n.pt')"
      ],
      "metadata": {
        "id": "7js_SCo9OZob",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1519f428-0aeb-4a83-a443-d13c46612f58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transferred 355/355 items from pretrained weights\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inicia o treinamento do modelo com os parâmetros fornecidos. O parâmetro `data` especifica o caminho para o arquivo de configuração do conjunto de dados YOLO (geralmente chamado de `data.yaml`). O parâmetro `task` especifica a tarefa a ser realizada, que neste caso é detecção de objetos. Outros parâmetros, como `epochs`, `imgsz` e `patience`, definem o número de épocas de treinamento, o tamanho da imagem e a paciência para o treinamento, respectivamente."
      ],
      "metadata": {
        "id": "NPYTKe2KX-ZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.train(data='/content/datasets/yolo-format/tobacco800/data.yaml', task='detect', epochs=300, imgsz=640, patience=100)"
      ],
      "metadata": {
        "id": "ITpTvd-CX9fB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Métricas de avaliação para o modelo treinado:\n",
        "\n",
        "*   `model.val()`: Esta função calcula as métricas de avaliação usando o conjunto de validação. Não são necessários argumentos, pois o conjunto de dados e as configurações são lembrados pelo modelo. Essa função retorna um objeto que contém várias métricas de avaliação.\n",
        "  *   `metrics.box.map`: Retorna a média da precisão média (mAP) para as áreas de interseção sobre a união (IoU) variando de 50% a 95% (map50-95).\n",
        "  *   `metrics.box.map50`: Retorna a média da precisão média (mAP) para a área de interseção sobre a união (IoU) de 50% (map50).\n",
        "  *   `metrics.box.map75`: Retorna a média da precisão média (mAP) para a área de interseção sobre a união (IoU) de 75% (map75).\n",
        "  *   `metrics.box.maps`: Retorna uma lista que contém a média da precisão média (mAP) para a área de interseção sobre a união (IoU) de 50% a 95% para cada categoria."
      ],
      "metadata": {
        "id": "0u-t0DLtZLyZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = model.val()\n",
        "metrics.box.map\n",
        "metrics.box.map50\n",
        "metrics.box.map75\n",
        "metrics.box.maps"
      ],
      "metadata": {
        "id": "f50-UUk4ZMWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "O resultado do treinamento para esta biblioteca está disponível [neste link](https://hub.ultralytics.com/models/Y581VHXyjNLCuoytDBqr), contendo todos os dados de validação."
      ],
      "metadata": {
        "id": "zRnXb_uvddqq"
      }
    }
  ]
}